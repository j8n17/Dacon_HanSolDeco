{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_df = pd.read_csv('../data/train.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정답 문장 임베딩 벡터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 문장들\n",
    "train_answers = train_df['answer'].tolist()\n",
    "\n",
    "embedding_model_name = \"upskyy/bge-m3-korean\"\n",
    "embedding_model = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "# 임베딩 생성\n",
    "train_answer_embeddings = embedding_model.encode(train_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코사인 유사도 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(embeddings):\n",
    "    \"\"\"\n",
    "    임베딩 배열(2차원, shape=(n, d))에 대해\n",
    "    벡터화된 코사인 유사도 행렬을 계산합니다.\n",
    "    \"\"\"\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    # 0으로 나누는 것을 방지하기 위해, 0인 경우 1로 치환\n",
    "    normed = embeddings / np.where(norms == 0, 1, norms)\n",
    "    similarity = np.dot(normed, normed.T)\n",
    "    # norm이 0인 경우 해당 행/열의 유사도를 0으로 설정\n",
    "    zero_norm_mask = (norms == 0).reshape(-1)\n",
    "    similarity[zero_norm_mask] = 0\n",
    "    similarity[:, zero_norm_mask] = 0\n",
    "    return similarity\n",
    "\n",
    "def jaccard_similarity_matrix(answers):\n",
    "    \"\"\"\n",
    "    문장 리스트에 대해 자카드 유사도 행렬을 계산합니다.\n",
    "    각 문장을 미리 단어 집합으로 변환한 후, 상삼각행렬만 계산합니다.\n",
    "    \"\"\"\n",
    "    n = len(answers)\n",
    "    token_sets = [set(answer.split()) for answer in answers]\n",
    "    jaccard_mat = np.zeros((n, n))\n",
    "    \n",
    "    for i in tqdm(range(n), desc=\"자카드 계산 진행\"):\n",
    "        for j in range(i + 1, n):\n",
    "            inter = len(token_sets[i] & token_sets[j])\n",
    "            union = len(token_sets[i] | token_sets[j])\n",
    "            sim = inter / union if union != 0 else 0\n",
    "            jaccard_mat[i, j] = sim\n",
    "            jaccard_mat[j, i] = sim\n",
    "    return jaccard_mat\n",
    "\n",
    "def select_sentence(answers, answer_embeddings):\n",
    "    \"\"\"\n",
    "    코사인 유사도와 자카드 유사도를 결합하여 각 문장의 평균 유사도를 계산한 후,\n",
    "    가장 높은 평균 유사도를 가지는 문장을 고정 문장으로 선택합니다.\n",
    "    \"\"\"\n",
    "    n = len(answers)\n",
    "    \n",
    "    # 전체 코사인 유사도 행렬 계산 (벡터화)\n",
    "    cos_sim = cosine_similarity_matrix(answer_embeddings)\n",
    "    \n",
    "    # 자카드 유사도 행렬 계산 (미리 전처리된 단어 집합 사용)\n",
    "    jaccard_sim = jaccard_similarity_matrix(answers)\n",
    "    \n",
    "    # 가중합: 코사인 유사도 0.7, 자카드 유사도 0.3\n",
    "    sim_matrix = 0.7 * cos_sim + 0.3 * jaccard_sim\n",
    "    \n",
    "    # 각 문장에 대한 평균 유사도 (자기 자신 제외)\n",
    "    avg_scores = sim_matrix.sum(axis=1) / (n - 1)\n",
    "    \n",
    "    # 평균 유사도가 가장 높은 문장 선택\n",
    "    selected_sentence_index = np.argmax(avg_scores)\n",
    "    score = avg_scores[selected_sentence_index]\n",
    "    \n",
    "    return cos_sim, jaccard_sim, selected_sentence_index, score\n",
    "\n",
    "cos_sim = cosine_similarity_matrix(train_answer_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim, jaccard_sim, selected_sentence_index, score = select_sentence(train_answers, train_answer_embeddings)\n",
    "print(f\"선정된 문장: {train_answers[selected_sentence_index]}, Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 행렬 저장\n",
    "np.save('../data/cos_sim_matrix.npy', cos_sim)\n",
    "np.save('../data/jaccard_sim_matrix.npy', jaccard_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대표 문장 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: 남은 인덱스 개수 -> 21399\n",
      "선택된 인덱스: 13050\n",
      "임계값 (50퍼센타일): 0.6929519772529602\n",
      "----------------------------------------\n",
      "Iteration 1: 남은 인덱스 개수 -> 10700\n",
      "선택된 인덱스: 13050\n",
      "임계값 (50퍼센타일): 0.7681925296783447\n",
      "----------------------------------------\n",
      "Iteration 2: 남은 인덱스 개수 -> 5350\n",
      "선택된 인덱스: 13050\n",
      "임계값 (50퍼센타일): 0.8115762174129486\n",
      "----------------------------------------\n",
      "Iteration 3: 남은 인덱스 개수 -> 2675\n",
      "선택된 인덱스: 13050\n",
      "임계값 (50퍼센타일): 0.8406871557235718\n",
      "----------------------------------------\n",
      "Iteration 4: 남은 인덱스 개수 -> 1338\n",
      "선택된 인덱스: 14390\n",
      "임계값 (50퍼센타일): 0.8665653169155121\n",
      "----------------------------------------\n",
      "Iteration 5: 남은 인덱스 개수 -> 669\n",
      "선택된 인덱스: 14390\n",
      "임계값 (50퍼센타일): 0.8919670581817627\n",
      "----------------------------------------\n",
      "Iteration 6: 남은 인덱스 개수 -> 335\n",
      "선택된 인덱스: 14390\n",
      "임계값 (50퍼센타일): 0.9097266793251038\n",
      "----------------------------------------\n",
      "Iteration 7: 남은 인덱스 개수 -> 168\n",
      "선택된 인덱스: 14390\n",
      "임계값 (50퍼센타일): 0.9256658256053925\n",
      "----------------------------------------\n",
      "Iteration 8: 남은 인덱스 개수 -> 84\n",
      "선택된 인덱스: 14390\n",
      "임계값 (50퍼센타일): 0.9371036291122437\n",
      "----------------------------------------\n",
      "Iteration 9: 남은 인덱스 개수 -> 42\n",
      "선택된 인덱스: 14390\n",
      "임계값 (50퍼센타일): 0.9487280249595642\n",
      "----------------------------------------\n",
      "Iteration 10: 남은 인덱스 개수 -> 21\n",
      "선택된 인덱스: 14390\n",
      "임계값 (50퍼센타일): 0.9545755982398987\n",
      "----------------------------------------\n",
      "Iteration 11: 남은 인덱스 개수 -> 11\n",
      "선택된 인덱스: 14390\n",
      "임계값 (50퍼센타일): 0.9586905837059021\n",
      "----------------------------------------\n",
      "Iteration 12: 남은 인덱스 개수 -> 6\n",
      "선택된 인덱스: 11380\n",
      "임계값 (50퍼센타일): 0.9655849635601044\n",
      "----------------------------------------\n",
      "Iteration 13: 남은 인덱스 개수 -> 3\n",
      "선택된 인덱스: 11380\n",
      "임계값 (50퍼센타일): 0.9933155179023743\n",
      "----------------------------------------\n",
      "Iteration 14: 남은 인덱스 개수 -> 2\n",
      "선택된 인덱스: 11380\n",
      "임계값 (50퍼센타일): 0.9966577589511871\n",
      "----------------------------------------\n",
      "최종 남은 인덱스: [11380]\n"
     ]
    }
   ],
   "source": [
    "# 'answer' 컬럼 기준으로 중복 제거\n",
    "train_df = train_df.drop_duplicates(subset=['answer'])\n",
    "\n",
    "# 예시: cosine_sim은 (n x n) 코사인 유사도 행렬입니다.\n",
    "cosine_sim = np.load(\"../data/cos_sim_matrix.npy\")\n",
    "\n",
    "# train_df의 인덱스를 기준으로 cosine_sim 행렬 재구성\n",
    "train_indices = train_df.index.values\n",
    "cosine_sim = cosine_sim[np.ix_(train_indices, train_indices)]\n",
    "\n",
    "# 초기 남은 인덱스 집합 (전체 인덱스)\n",
    "remaining_indices = np.arange(cosine_sim.shape[0])\n",
    "iteration = 0\n",
    "\n",
    "while len(remaining_indices) > 1:\n",
    "    print(f\"Iteration {iteration}: 남은 인덱스 개수 -> {len(remaining_indices)}\")\n",
    "    \n",
    "    # 남은 인덱스에 해당하는 부분 행렬(submatrix) 선택\n",
    "    submatrix = cosine_sim[np.ix_(remaining_indices, remaining_indices)]\n",
    "    \n",
    "    # 각 행의 합 계산 (남은 인덱스에 한정)\n",
    "    row_sums = submatrix.sum(axis=1)\n",
    "    \n",
    "    # 가장 합이 큰 인덱스 선택 (submatrix 내 상대 인덱스)\n",
    "    max_idx_in_remaining = np.argmax(row_sums)\n",
    "    \n",
    "    # 원래 전체 행렬 상의 실제 인덱스\n",
    "    chosen_index = remaining_indices[max_idx_in_remaining]\n",
    "    # 중복 제거 전 원래 인덱스로 변환\n",
    "    original_chosen_index = train_indices[chosen_index]\n",
    "    print(f\"선택된 인덱스: {original_chosen_index}\")\n",
    "    \n",
    "    # 선택한 인덱스와 남은 인덱스들 간의 코사인 유사도 값 추출\n",
    "    sim_values = cosine_sim[chosen_index, remaining_indices]\n",
    "    \n",
    "    # 상위 50% 기준 임계값 (중앙값) 계산\n",
    "    threshold = np.percentile(sim_values, 50)\n",
    "    print(f\"임계값 (50퍼센타일): {threshold}\")\n",
    "    \n",
    "    # 임계값 이상인 인덱스(자기 자신 포함)만 남기기\n",
    "    remaining_indices = remaining_indices[sim_values >= threshold]\n",
    "    \n",
    "    iteration += 1\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# 최종 남은 인덱스를 중복 제거 전 원래 인덱스로 변환\n",
    "original_remaining_indices = train_indices[remaining_indices]\n",
    "print(\"최종 남은 인덱스:\", original_remaining_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작업전 안전교육 강화 및 작업장 위험요소 점검을 통한 재발 방지와 안전관리 교육 철저를 통한 향후 조치 계획.\n",
      "안전교육 실시와 작업 시 안전관리 철저를 통한 재발 방지 대책 및 향후 조치 계획.\n",
      "현장 관리 철저와 작업자 안전교육 실시를 통한 재발 방지 대책 및 향후 조치 계획.\n"
     ]
    }
   ],
   "source": [
    "print(train_df.loc[13050, 'answer'])\n",
    "print(train_df.loc[14390, 'answer'])\n",
    "print(train_df.loc[11380, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "const_safety",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
